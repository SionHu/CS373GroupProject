# **Installment and Running Instructions**

***

### This is the Installment Requirements that are needed for this project.
### For those can be that installed via PIP, please refer to to _requirements.txt_ in the the same folder and type `pip install requirements.txt`, which will download the packages and their dependencies. 

### For training a model or validate on **Facenet** or __YOLOv3__, a gpu version of Tensorflow and CUDA is recommended. Please follow the download instructions of Tensorflow: https://www.tensorflow.org/install/ (GPU version requires CUDA and Tensorflow will also show how to install)

**If Using a GPU on Facenet, please add:**
```python
import os
os.environ["CUDA_VISIBLE_DEVICES"] = '0'
```
**at the import section of the python files that are desired to run with GPU**

## 1. YOLOv3
**Darknet** [Repo](https://github.com/pjreddie/darknet): `git clone https://github.com/pjreddie/darknet.git`

- To run Yolov3 with darkent, the Yolov3 pre-trained model can be downloaded [here](wget https://pjreddie.com/media/files/yolov3.weights)
- Since we have trained two models (Although soon found out the presicions on them were low due to the limiation of tools) in `Model/Set_A` and `Model/Set_B`
- Put one of the `.weights` model in the root folder of `darknet/` folder, and put `obj.names` and `obj.data` from `Model folder` in `darknet/data/`, and `yolo-obj.cfg` in `darknet/cfg/`.
- Choose `train*.txt` and `test*.txt` from `kfoldtxt/` folder and copy to `darknet/` repo, where **'*'** is the same letter from _'A'_ to _'E'_. These two files will tell darknet to find the images used for training and testing. 
- Copy all the images and txt files in `dataset/Images/001/` to `darknet/data/Bush`, note if there is no such folder simplely create one.

    **For information on how to train or detect, please refer to _readme.md_ from this [repo](https://github.com/AlexeyAB/darknet)** 
	Useful commands

## 2. Facenet 
**Facenet** [repo](https://github.com/davidsandberg/facenet): ` git clone https://github.com/davidsandberg/facenet.git`

- Set environment variable PYTHONPATH that used in facenet: `export PYTHONPATH=[...]/facenet/src`, where `[...]` should be replaced with the directory where the cloned facenet repo resides.
- For training, put the `datasets` and `Model` folder in the same level of `facenet` repo so that facenet executable could be founded on . 
- Some of the commands can be founded below (**Note**: the commands here are only for reference, running directly might have some issues)

    **For more information on training and validating, please refer to [wiki](https://github.com/davidsandberg/facenet/wiki)
	
	Useful commands:
	
		- Building a model(.pb) from metadata: python src/freeze_graph.py ../models/facenet1/%latest path that contains metadata%/ %absolute_Path/*.pb --> * is the filename of your favorite
		
		- 
### Validation
- The validation files have been generated according to Facenet github, and stored in the folder Validation. The generated files are using the image dataset in "validation_images". However, if user wants to try different datasest, the following are the steps need to be followed: 

* Align the LFW dataset -> test_mtcnnpy_160. An example code is shown below: 
	python src/align/align_dataset_mtcnn.py \
		~/Documents/GitHub/datasets/test/raw/ \
		~/Documents/GitHub/datasets/test/test_mtcnnpy_160 \
		--image_size 160 \
		--margin 32 \
		--random_order \
		--gpu_memory_fraction 0.25

* Use generate_pairs.txt to generate customized pair.txt -> /pairs. Piars folder contains pairs with different number of (mis)match. For detail of (mis)matc. An example command is shoen as bellow:  
	python3 generate_pairs.py \
		--image_dir /Users/Sion/Documents/GitHub/datasets/test/raw/ \
		--pairs_file_name /Users/Sion/Documents/GitHub/datasets/test/test_pair_20.txt  \
		--num_folds 2 \
		--num_matches_mismatches 20

* Validate by testing. Follow the steps on Facenet. An example code is shown as follow: 
	python src/validate_on_lfw.py  \
		~/Documents/GitHub/datasets/test/test_mtcnnpy_250 \
		~/Documents/GitHub/models/20181201-181023 \
		--distance_metric 1 \
		--use_flipped_images \
		--subtract_mean \
		--use_fixed_image_standardization \
		--lfw_pairs /Users/Sion/Documents/GitHub/datasets/test/test_pair_20.txt \
		--lfw_batch_size 1 \
		--lfw_nrof_folds 2`


## 3. SVM 
Run the test.py that is located in `SVM_part/`, The pre-processed dataset images using are located in `SVM_part/data/`



